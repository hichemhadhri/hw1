{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f19621",
   "metadata": {},
   "source": [
    "# Homework 1 (HW1)\n",
    "\n",
    "By the end of this homework, we expect you to be able to:\n",
    "\n",
    "- Load data and handle data using pandas;\n",
    "- Navigate the documentation of Python packages by yourself;\n",
    "- Filter and tidy up noisy real-world datasets;\n",
    "- Aggregate your data in different (and hopefully helpful) ways; \n",
    "- Create meaningful visualizations to analyze the data;\n",
    "\n",
    "---\n",
    "\n",
    "## Important Dates\n",
    "\n",
    "- Homework release: Fri 14 Oct 2022\n",
    "- **Homework due**: Sat 29 Oct 2022, 23:59\n",
    "- Grade release: Mon 07 Nov 2022\n",
    "\n",
    "---\n",
    "\n",
    "##  Some rules\n",
    "\n",
    "1. You are allowed to use any built-in Python library that comes with Anaconda. If you want to use an external library, \n",
    "you may do so, but must justify your choice.\n",
    "2. Make sure you use the `data` folder provided in the repository in read-only mode. (Or alternatively, be sure you \n",
    "donâ€™t change any of the files.)\n",
    "3. Be sure to provide a textual description of your thought process, the assumptions you made, the solution you \n",
    "implemented, and explanations for your answers. A notebook that only has code cells will not suffice.\n",
    "4. For questions containing the **/Discuss:/** prefix, answer not with code, but with a textual explanation\n",
    " (**in markdown**).\n",
    "5. Back up any hypotheses and claims with data, since this is an important aspect of the course.\n",
    "6. Please write all your comments in English, and use meaningful variable names in your code. Your repo should have a \n",
    "single notebook (plus the required data files) in the *master/main* branch. If there are multiple notebooks present, \n",
    "we will **not grade** anything.\n",
    "7. We will **not run your notebook for you**! Rather, we will grade it as is, which means that only the results \n",
    "contained in your evaluated code cells will be considered, and we will not see the results in unevaluated code cells. \n",
    "Thus, be sure to hand in a **fully-run and evaluated notebook**. In order to check whether everything looks as intended,\n",
    " you can check the rendered notebook on the GitHub website once you have pushed your solution there.\n",
    "8. In continuation to the previous point, interactive plots, such as those generated using `plotly`, should be \n",
    "**strictly avoided**!\n",
    "9. Make sure to print results or dataframes that confirm you have properly addressed the task.\n",
    "\n",
    "---\n",
    "\n",
    "In this homework, we will analyze data from A/B tests of headlines conducted by Upworthy from January 2013 to April 2015 to study whether the language used in the headline determines the number of people that will read the associated news piece. The homework contains four tasks: in task 1, we will process the data; in task 2, we will extract meaningful signals from the data; in task 3, we will test whether the language of headlines impacts their success; and in task 4, we will explore the heterogeneity of this effects (e.g., does it vary through time?).\n",
    "\n",
    "\n",
    "### **What is an A/B test?** \n",
    "A/B tests are experiments that compare two scenarios (e.g., scenario A vs. scenario B). \n",
    "They test subjects' responses to each of the variants to determine which is more effective ([read more about A/B tests on Wikipedia](https://en.wikipedia.org/wiki/A/B_testing)). \n",
    "A/B tests allow us to draw conclusions about the different scenarios by randomizing exposure to them, e.g., one could flip a coin and assign a user to scenario A if it lands heads and to B if it lands tails. \n",
    "Since exposure is randomized, we can be confident that the scenarios are the sole explanation for statistically significant differences in subjects' responses (if they exist). \n",
    "In theory, A/B testing refers to an experiment that compares two scenarios; however, in practice, the term is also used when we compare multiple scenarios (e.g., A vs. B vs. C), although the more precise terminology would be to call such an experiment a \"multinomial test.\"\n",
    "\n",
    "### **How were A/B tests used by Upworthy?** \n",
    "Upworthy used A/B testing to increase news readership, conducting experiments for each published news piece. \n",
    "In each experiment, they created multiple \"packages\" of stimuli, varying headlines, images, excerpts, and ledes for the same news piece. \n",
    "Different \"packages\" were shown on their (now defunct) website to engage users with the news pieces they produced. Upworthy found \"the best\" package by conducting A/B tests, showing different packages to different users, and measuring how often users clicked on each version. \n",
    "Below, we show three \"packages\" used by Upworthy in an experiment, each with a different headline for the same news piece. \n",
    "Upworthy randomized users that visited their website saw one of the three versions of the headline below. Then, they measured the percentage of times users in each scenario clicked to read the news. \n",
    "The headline with the highest percentage of clicks per view (click through rate) was then declared the \"winner\" and became the default for all visitors.\n",
    "\n",
    "![Example A/B test](example.png)\n",
    "\n",
    " ### **Where does this data come from?** \n",
    " \n",
    " From a paper [1].\n",
    "\n",
    "[1] Matias, J.N., Munger, K., Le Quere, M.A. et al. The Upworthy Research Archive, a time series of 32,487 experiments in U.S. media. Sci Data 8, 195 (2021). https://doi.org/10.1038/s41597-021-00934-7\n",
    "\n",
    "### **Where can I find this data?**  \n",
    "\n",
    "You can find it in the `/data/` folder.\n",
    "\n",
    "### **Terminology**\n",
    "\n",
    "- **News piece:** A news article. In the dataset considered, these were all produced by Upworthy.\n",
    "- **Package:** The set of visual stimuli inviting the user to read an article. The figure above shows a package with a headline and an image. At times, there was an excerpt of the article also shown in the package and/or the lede, i.e., [\"the introductory section of a news story that is intended to entice the reader to read the full story.\"](https://www.merriam-webster.com/words-at-play/bury-the-lede-versus-lead#:~:text=In%20journalism%2C%20the%20lede%20refers,machines%20began%20disappearing%20from%20newsrooms.)\n",
    "- **Experiment:** Each experiment is an A/B test (or multinomial test, to be more precise) comparing how users reacted to different \"packages.\" Experiments measured two things: 1) how many users were shown each package; and 2) how many individuals clicked each package.\n",
    "\n",
    "### **Data description**\n",
    "\n",
    "| Column name          | Description                                                                                                                                                                                       |   |   |   |\n",
    "|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---|---|---|\n",
    "| created_at           | Time the package was created (timezone unknown)                                                                                                                                                   |   |   |   |\n",
    "| test_week            | Week the package was created, a variable constructed by the archive creators for stratified random sampling                                                                                       |   |   |   |\n",
    "| clickability_test_id | The test ID. Viewers were randomly assigned to packages with the same test ID                                                                                                                     |   |   |   |\n",
    "| impressions          | The number of viewers who were assigned to this package. The total number of participants for a given test is the sum of impressions for all packages that share the same clickability_test_id    |   |   |   |\n",
    "| headline             | The headline being tested                                                                                                                                                                         |   |   |   |\n",
    "| eyecatcher_id        | Image ID. Image files are not available. Packages that shared the same image have the same eyecatcher_id                                                                                          |   |   |   |\n",
    "| clicks               | The number of viewers (impressions) that clicked on the package. The clickrate for a given package is the number of clicks divided by the number of impressions                                   |   |   |   |\n",
    "| excerpt              | Article excerpt                                                                                                                                                                                   |   |   |   |\n",
    "| lede                 | The opening sentence or paragraph of the story                                                                                                                                                    |   |   |   |\n",
    "| slug                 | Internal name for the web address                                                                                                                                                                 |   |   |   |\n",
    "| share_text           | Summary for display on social media when the article is shared. This was not shown in tests, since tests were conducted on the Upworthy website                                                   |   |   |   |\n",
    "| square               | When used, part of the same social media sharing suggestion as the share text                                                                                                                     |   |   |   |\n",
    "| significance         | NOT an estimate of statistical significance; a complex, inconsistent calculation that compared the clicks on a package to the clicks on all previous packages that were fielded on the same pages |   |   |   |\n",
    "| first_place          | Along with significance, shown to editors to guide decisions about what test to choose                                                                                                            |   |   |   |\n",
    "| winner               | Whether a package was selected by editors to be used on the Upworthy site after the test                                                                                                          |   |   |   |\n",
    "| updated_at           | The last time the package was updated in the Upworthy system                                                                                                                                      |   |   |   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b640175",
   "metadata": {},
   "source": [
    "## Task 1: Getting familiar with the data\n",
    "\n",
    "Your first task is to conduct initial analyses to understand the data and process it in a way that will allow us to more easily answer our key question: *how does the language of a headline determine its success?*\n",
    "\n",
    "1.1 Load the data into memory using pandas and print the first lines to get a sense of it.\n",
    "\n",
    "1.2 Each experiment comparing different versions of the same news piece (\"packages\") has a unique identifier (`clickability_test_id` column). \n",
    "Calculate how many different experiments were conducted in this dataset and, on average, how many packages were considered per experiment. \n",
    "Last, plot the distribution of packages per experiment with a visualization of your choice.\n",
    "\n",
    "1.3 A common way to measure success in online A/B tests is what is called \"the clickthrough rate.\"\n",
    "Given that often A/B tests are created to find what engages users (here, \"packages\" of headlines, images, etc), we would expect that a \"good\" package makes people click often. \n",
    "Create a column named `ctr` by dividing the number of clicks a package received (`clicks` column) by the number of impressions it received (`impressions` column).\n",
    "\n",
    "1.4 Packages varied any combination of the headline (`headline` column), the excerpt (`excerpt`), the first sentence of the article (`lede`), and the image that illustrates the news piece (`eyecatcher_id`, a hash per image). \n",
    "But we want to isolate the effect of the headline on the clickthrough rate. To do that, create a new dataframe where you filter all experiments where only one headline is present. \n",
    "Print the length of this new dataframe and how many experiments were discarded in the filtering process.\n",
    "\n",
    "1.5 For comparison, repeat the procedure described in **T1.4** with the `eyecatcher_id` column, i.e., create a dataframe considering only experiments that vary the image. \n",
    "Again, print the length of this new dataframe and how many experiments were discarded in the filtering process.\n",
    "\n",
    "1.6 **Discuss:** Considering the answers to questions **T1.4** and **T1.4**, what can we say about the different versions of the news tested by Upworthy?\n",
    "\n",
    "1.7 For our subsequent analysis, we want to compare the causal effect of headlines on the success of a news piece. \n",
    "For that, we can compare pairs of packages with the same `eyecatcher_id`, `lede`, and `excerpt`, but different `headlines`.\n",
    "Note that this means that if an experiment considered 5 different headlines and did not vary any other stimulus, we would have 5C2 (i.e., 5 choose 2, 10) pairs to consider.\n",
    "Create a dataset where:\n",
    "- each row corresponds to a pair of packages with different `headline` but the same `eyecatcher_id`, `lede`, and `excerpt`. \n",
    "- there are columns containing the headlines of each of the news versions (`headline1`, `headline2`) and the clickthrough rate of each of the news versions (`ctr1`, `ctr2`). \n",
    "- the columns `headline1` and `ctr1` contain the data associated with the news version with the highest clickthrough rate. Print the first columns of your newly created dataframe, as well as its length.\n",
    "-  the columns where the two news pieces had exactly the same clickthrough rate should be filtered out (this is for simplicity's sake).\n",
    "-  the column `date_created` contains the date when the news version with the highest clickthrough rate was created.\n",
    "\n",
    "1.8 To get a sense of the impact of headline change, measure the average difference per pair between the most clicked-through (`ctr1`) and the least clicked-through headline (`ctr2`), as well as the average clickthrough rate for the least clicked through headline (`ctr2`). \n",
    "\n",
    "1.9 **Discuss:** Considering your answer to **T1.8**, and assuming the average differences in clickthrough rates between pairs are statistically significant, do you think that headlines are impactful in the news business? Justify with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560cc150",
   "metadata": {},
   "source": [
    "1.1 Load the data into memory using pandas and print the first lines to get a sense of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a9f611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>clickability_test_id</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>headline</th>\n",
       "      <th>lede</th>\n",
       "      <th>slug</th>\n",
       "      <th>eyecatcher_id</th>\n",
       "      <th>impressions</th>\n",
       "      <th>clicks</th>\n",
       "      <th>significance</th>\n",
       "      <th>first_place</th>\n",
       "      <th>winner</th>\n",
       "      <th>share_text</th>\n",
       "      <th>square</th>\n",
       "      <th>test_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-11-20 06:43:16.005</td>\n",
       "      <td>2016-04-02 16:33:38.062</td>\n",
       "      <td>546d88fb84ad38b2ce000024</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "      <td>They're Being Called 'Walmart's Worst Nightmar...</td>\n",
       "      <td>&lt;p&gt;When I saw *why* people are calling them \"W...</td>\n",
       "      <td>theyre-being-called-walmarts-worst-nightmare-a...</td>\n",
       "      <td>546d6fa19ad54eec8d00002d</td>\n",
       "      <td>3052</td>\n",
       "      <td>150</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Anyone who's ever felt guilty about shopping a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-11-20 06:54:36.335</td>\n",
       "      <td>2016-04-02 16:25:54.027</td>\n",
       "      <td>546d902c26714c6c44000039</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "      <td>This Is What Sexism Against Men Sounds Like</td>\n",
       "      <td>&lt;p&gt;DISCLOSURE: I'm a dude. I have cried on mul...</td>\n",
       "      <td>this-is-what-sexism-against-men-sounds-like-am...</td>\n",
       "      <td>546bc55335992b86c8000043</td>\n",
       "      <td>3526</td>\n",
       "      <td>90</td>\n",
       "      <td>4.1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>If you ever wondered, \"but what about the men?...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-11-20 06:54:57.878</td>\n",
       "      <td>2016-04-02 16:31:45.671</td>\n",
       "      <td>546d902c26714c6c44000039</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "      <td>This Is What Sexism Against Men Sounds Like</td>\n",
       "      <td>&lt;p&gt;DISCLOSURE: I'm a dude. I have cried on mul...</td>\n",
       "      <td>this-is-what-sexism-against-men-sounds-like-am...</td>\n",
       "      <td>546d900426714cd2dd00002e</td>\n",
       "      <td>3506</td>\n",
       "      <td>120</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>If you ever wondered, \"but what about the men?...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-11-20 06:55:07.212</td>\n",
       "      <td>2016-04-02 16:25:54.029</td>\n",
       "      <td>546d902c26714c6c44000039</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "      <td>This Is What Sexism Against Men Sounds Like</td>\n",
       "      <td>&lt;p&gt;DISCLOSURE: I'm a dude. I have cried on mul...</td>\n",
       "      <td>this-is-what-sexism-against-men-sounds-like-am...</td>\n",
       "      <td>546d900426714c6c44000038</td>\n",
       "      <td>3380</td>\n",
       "      <td>98</td>\n",
       "      <td>25.3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>If you ever wondered, \"but what about the men?...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-11-20 06:55:20.347</td>\n",
       "      <td>2016-04-02 16:25:54.032</td>\n",
       "      <td>546d902c26714c6c44000039</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "      <td>This Is What Sexism Against Men Sounds Like</td>\n",
       "      <td>&lt;p&gt;DISCLOSURE: I'm a dude. I have cried on mul...</td>\n",
       "      <td>this-is-what-sexism-against-men-sounds-like-am...</td>\n",
       "      <td>546d900426714c1ad900001e</td>\n",
       "      <td>3465</td>\n",
       "      <td>75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>If you ever wondered, \"but what about the men?...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at              updated_at      clickability_test_id  \\\n",
       "0 2014-11-20 06:43:16.005 2016-04-02 16:33:38.062  546d88fb84ad38b2ce000024   \n",
       "1 2014-11-20 06:54:36.335 2016-04-02 16:25:54.027  546d902c26714c6c44000039   \n",
       "2 2014-11-20 06:54:57.878 2016-04-02 16:31:45.671  546d902c26714c6c44000039   \n",
       "3 2014-11-20 06:55:07.212 2016-04-02 16:25:54.029  546d902c26714c6c44000039   \n",
       "4 2014-11-20 06:55:20.347 2016-04-02 16:25:54.032  546d902c26714c6c44000039   \n",
       "\n",
       "                            excerpt  \\\n",
       "0  Things that matter. Pass 'em on.   \n",
       "1  Things that matter. Pass 'em on.   \n",
       "2  Things that matter. Pass 'em on.   \n",
       "3  Things that matter. Pass 'em on.   \n",
       "4  Things that matter. Pass 'em on.   \n",
       "\n",
       "                                            headline  \\\n",
       "0  They're Being Called 'Walmart's Worst Nightmar...   \n",
       "1        This Is What Sexism Against Men Sounds Like   \n",
       "2        This Is What Sexism Against Men Sounds Like   \n",
       "3        This Is What Sexism Against Men Sounds Like   \n",
       "4        This Is What Sexism Against Men Sounds Like   \n",
       "\n",
       "                                                lede  \\\n",
       "0  <p>When I saw *why* people are calling them \"W...   \n",
       "1  <p>DISCLOSURE: I'm a dude. I have cried on mul...   \n",
       "2  <p>DISCLOSURE: I'm a dude. I have cried on mul...   \n",
       "3  <p>DISCLOSURE: I'm a dude. I have cried on mul...   \n",
       "4  <p>DISCLOSURE: I'm a dude. I have cried on mul...   \n",
       "\n",
       "                                                slug  \\\n",
       "0  theyre-being-called-walmarts-worst-nightmare-a...   \n",
       "1  this-is-what-sexism-against-men-sounds-like-am...   \n",
       "2  this-is-what-sexism-against-men-sounds-like-am...   \n",
       "3  this-is-what-sexism-against-men-sounds-like-am...   \n",
       "4  this-is-what-sexism-against-men-sounds-like-am...   \n",
       "\n",
       "              eyecatcher_id  impressions  clicks  significance  first_place  \\\n",
       "0  546d6fa19ad54eec8d00002d         3052     150         100.0         True   \n",
       "1  546bc55335992b86c8000043         3526      90           4.1        False   \n",
       "2  546d900426714cd2dd00002e         3506     120         100.0         True   \n",
       "3  546d900426714c6c44000038         3380      98          25.3        False   \n",
       "4  546d900426714c1ad900001e         3465      75           0.2        False   \n",
       "\n",
       "   winner                                         share_text square  test_week  \n",
       "0    True  Anyone who's ever felt guilty about shopping a...    NaN     201446  \n",
       "1   False  If you ever wondered, \"but what about the men?...    NaN     201446  \n",
       "2   False  If you ever wondered, \"but what about the men?...    NaN     201446  \n",
       "3   False  If you ever wondered, \"but what about the men?...    NaN     201446  \n",
       "4   False  If you ever wondered, \"but what about the men?...    NaN     201446  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import ttest_ind, ttest_rel, bootstrap\n",
    "from statsmodels.stats import diagnostic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "data_folder = './Data/'\n",
    "\n",
    "packages = pd.read_csv(data_folder+'upworthy.csv.gz', parse_dates=['created_at','updated_at'],na_values=['Nan'])\n",
    "packages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee7d498",
   "metadata": {},
   "source": [
    "1.2 Each experiment comparing different versions of the same news piece (\"packages\") has a unique identifier (clickability_test_id column). Calculate how many different experiments were conducted in this dataset and, on average, how many packages were considered per experiment. Last, plot the distribution of packages per experiment with a visualization of your choice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac524a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of experiments is 4822 with on averange 4.27 packages considered per experiment and a variance of 2.1 packages \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_by_id = packages.groupby('clickability_test_id')\n",
    "count_by_experiment = packages.groupby('clickability_test_id').count()['created_at']\n",
    "\n",
    "nb_experiment = count_by_experiment.count()\n",
    "mean_nb_experiment = count_by_experiment.mean()\n",
    "variance_nb_experiment = count_by_experiment.var()\n",
    "print(\"The total number of experiments is %d with on averange %0.2f packages considered per experiment and a variance of %0.1f packages \" % (nb_experiment,mean_nb_experiment,variance_nb_experiment ))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle('Number of packages per experiment')\n",
    "ax1.hist(count_by_experiment.values, bins = 40 )\n",
    "\n",
    "ax1.set(xlabel='Number of packages', ylabel=\"Number of experiments\", yscale = \"log\") \n",
    "ax2.boxplot(count_by_experiment)\n",
    "ax2 = ax2.set(xticks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a8771b",
   "metadata": {},
   "source": [
    "1.3 A common way to measure success in online A/B tests is what is called \"the clickthrough rate.\" Given that often A/B tests are created to find what engages users (here, \"packages\" of headlines, images, etc), we would expect that a \"good\" package makes people click often. Create a column named ctr by dividing the number of clicks a package received (clicks column) by the number of impressions it received (impressions column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451e5d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>clickability_test_id</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>headline</th>\n",
       "      <th>lede</th>\n",
       "      <th>slug</th>\n",
       "      <th>eyecatcher_id</th>\n",
       "      <th>impressions</th>\n",
       "      <th>clicks</th>\n",
       "      <th>significance</th>\n",
       "      <th>first_place</th>\n",
       "      <th>winner</th>\n",
       "      <th>share_text</th>\n",
       "      <th>square</th>\n",
       "      <th>test_week</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7310</th>\n",
       "      <td>2013-07-08 21:20:09.751</td>\n",
       "      <td>2016-04-02 16:27:08.742</td>\n",
       "      <td>51db2af3b96d816dea00825f</td>\n",
       "      <td>A famous actor makes a frightening discovery a...</td>\n",
       "      <td>Dustin Hoffman Breaks Down Trying To Explain S...</td>\n",
       "      <td>&lt;p&gt;Back in the day, for those of you younger f...</td>\n",
       "      <td>dustin-hoffman-breaks-down-trying-to-explain-s...</td>\n",
       "      <td>5332bcd71fae79f09f00746c</td>\n",
       "      <td>1661</td>\n",
       "      <td>226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hoffman9.jpg</td>\n",
       "      <td>201327</td>\n",
       "      <td>0.136063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7545</th>\n",
       "      <td>2013-07-18 19:57:18.439</td>\n",
       "      <td>2016-04-02 16:27:13.724</td>\n",
       "      <td>51e8482dd0637d55cf000a49</td>\n",
       "      <td>The Daily Show rarely get this mad, but when t...</td>\n",
       "      <td>It's Rare That The Daily Show Slips Out Of Sat...</td>\n",
       "      <td>&lt;p&gt;\\n\\t                Leave it to the The Dai...</td>\n",
       "      <td>its-rare-that-the-daily-show-slips-out-of-sati...</td>\n",
       "      <td>5332bd531fae79f09f007fb0</td>\n",
       "      <td>2252</td>\n",
       "      <td>300</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oliver4.jpg</td>\n",
       "      <td>201328</td>\n",
       "      <td>0.133215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7307</th>\n",
       "      <td>2013-07-08 21:18:24.892</td>\n",
       "      <td>2016-04-02 16:27:08.734</td>\n",
       "      <td>51db2af3b96d816dea00825f</td>\n",
       "      <td>A famous actor makes a frightening discovery a...</td>\n",
       "      <td>Dustin Hoffman Breaks Down Crying Trying To Ex...</td>\n",
       "      <td>&lt;p&gt;Back in the day, for those of you younger f...</td>\n",
       "      <td>dustin-hoffman-breaks-down-crying-trying-to-ex...</td>\n",
       "      <td>5332bcd71fae79f09f00746c</td>\n",
       "      <td>1536</td>\n",
       "      <td>196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hoffman9.jpg</td>\n",
       "      <td>201327</td>\n",
       "      <td>0.127604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7542</th>\n",
       "      <td>2013-07-18 19:56:33.946</td>\n",
       "      <td>2016-04-02 16:27:13.717</td>\n",
       "      <td>51e8482dd0637d55cf000a49</td>\n",
       "      <td>The Daily Show rarely get this mad, but when t...</td>\n",
       "      <td>It's Rare That The Daily Show Slips Out Of Sat...</td>\n",
       "      <td>&lt;p&gt;\\n\\t                 Leave it to the The Da...</td>\n",
       "      <td>its-rare-that-the-daily-show-slips-out-of-sati...</td>\n",
       "      <td>5332bd531fae79f09f007fad</td>\n",
       "      <td>2200</td>\n",
       "      <td>279</td>\n",
       "      <td>79.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oliver2.jpg</td>\n",
       "      <td>201328</td>\n",
       "      <td>0.126818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16575</th>\n",
       "      <td>2014-09-17 20:55:13.084</td>\n",
       "      <td>2016-04-02 16:30:41.428</td>\n",
       "      <td>5419ed6f3088cfcf1f0000c0</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "      <td>A Teen Comes Out To His Mom But His Mom Actual...</td>\n",
       "      <td>&lt;p&gt;Coming out can be pretty scary for lots of ...</td>\n",
       "      <td>a-teen-comes-out-to-his-mom-but-his-mom-actual...</td>\n",
       "      <td>5418e71f3088cf5bfc000023</td>\n",
       "      <td>6602</td>\n",
       "      <td>811</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201437</td>\n",
       "      <td>0.122842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   created_at              updated_at  \\\n",
       "7310  2013-07-08 21:20:09.751 2016-04-02 16:27:08.742   \n",
       "7545  2013-07-18 19:57:18.439 2016-04-02 16:27:13.724   \n",
       "7307  2013-07-08 21:18:24.892 2016-04-02 16:27:08.734   \n",
       "7542  2013-07-18 19:56:33.946 2016-04-02 16:27:13.717   \n",
       "16575 2014-09-17 20:55:13.084 2016-04-02 16:30:41.428   \n",
       "\n",
       "           clickability_test_id  \\\n",
       "7310   51db2af3b96d816dea00825f   \n",
       "7545   51e8482dd0637d55cf000a49   \n",
       "7307   51db2af3b96d816dea00825f   \n",
       "7542   51e8482dd0637d55cf000a49   \n",
       "16575  5419ed6f3088cfcf1f0000c0   \n",
       "\n",
       "                                                 excerpt  \\\n",
       "7310   A famous actor makes a frightening discovery a...   \n",
       "7545   The Daily Show rarely get this mad, but when t...   \n",
       "7307   A famous actor makes a frightening discovery a...   \n",
       "7542   The Daily Show rarely get this mad, but when t...   \n",
       "16575                   Things that matter. Pass 'em on.   \n",
       "\n",
       "                                                headline  \\\n",
       "7310   Dustin Hoffman Breaks Down Trying To Explain S...   \n",
       "7545   It's Rare That The Daily Show Slips Out Of Sat...   \n",
       "7307   Dustin Hoffman Breaks Down Crying Trying To Ex...   \n",
       "7542   It's Rare That The Daily Show Slips Out Of Sat...   \n",
       "16575  A Teen Comes Out To His Mom But His Mom Actual...   \n",
       "\n",
       "                                                    lede  \\\n",
       "7310   <p>Back in the day, for those of you younger f...   \n",
       "7545   <p>\\n\\t                Leave it to the The Dai...   \n",
       "7307   <p>Back in the day, for those of you younger f...   \n",
       "7542   <p>\\n\\t                 Leave it to the The Da...   \n",
       "16575  <p>Coming out can be pretty scary for lots of ...   \n",
       "\n",
       "                                                    slug  \\\n",
       "7310   dustin-hoffman-breaks-down-trying-to-explain-s...   \n",
       "7545   its-rare-that-the-daily-show-slips-out-of-sati...   \n",
       "7307   dustin-hoffman-breaks-down-crying-trying-to-ex...   \n",
       "7542   its-rare-that-the-daily-show-slips-out-of-sati...   \n",
       "16575  a-teen-comes-out-to-his-mom-but-his-mom-actual...   \n",
       "\n",
       "                  eyecatcher_id  impressions  clicks  significance  \\\n",
       "7310   5332bcd71fae79f09f00746c         1661     226           0.0   \n",
       "7545   5332bd531fae79f09f007fb0         2252     300         100.0   \n",
       "7307   5332bcd71fae79f09f00746c         1536     196           0.0   \n",
       "7542   5332bd531fae79f09f007fad         2200     279          79.2   \n",
       "16575  5418e71f3088cf5bfc000023         6602     811         100.0   \n",
       "\n",
       "       first_place  winner share_text        square  test_week       ctr  \n",
       "7310         False   False        NaN  hoffman9.jpg     201327  0.136063  \n",
       "7545          True   False        NaN   oliver4.jpg     201328  0.133215  \n",
       "7307         False   False        NaN  hoffman9.jpg     201327  0.127604  \n",
       "7542         False   False        NaN   oliver2.jpg     201328  0.126818  \n",
       "16575         True   False        NaN           NaN     201437  0.122842  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packages['ctr']= packages.apply(lambda row: row['clicks']/row['impressions'], axis=1)\n",
    "packages.sort_values(by='ctr', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dfc710",
   "metadata": {},
   "source": [
    "1.4 Packages varied any combination of the headline (headline column), the excerpt (excerpt), the first sentence of the article (lede), and the image that illustrates the news piece (eyecatcher_id, a hash per image). But we want to isolate the effect of the headline on the clickthrough rate. To do that, create a new dataframe where you filter all experiments where only one headline is present. Print the length of this new dataframe and how many experiments were discarded in the filtering process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8ca9255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new dataframe length is 11600 and were retained 2586 experiments and 2236 experiments were dropped \n"
     ]
    }
   ],
   "source": [
    "### Packages where there is more than one headline \n",
    "#not_unique_headline_df = packages.groupby(by=['clickability_test_id']).filter(lambda x : len(x.groupby('headline'))!=1)\n",
    "not_unique_headline_df = packages.groupby(by=['clickability_test_id']).filter(lambda x : x['headline'].nunique() != 1)\n",
    "\n",
    "### Number of expermient where there is more than one headline \n",
    "not_unique_headline_exp_count = not_unique_headline_df.groupby('clickability_test_id').count()['created_at'].count()\n",
    "print(\"The new dataframe length is %d and were retained %d experiments and %d experiments were dropped \" % (len(not_unique_headline_df), not_unique_headline_exp_count,nb_experiment-not_unique_headline_exp_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40ed3d",
   "metadata": {},
   "source": [
    "1.5 For comparison, repeat the procedure described in T1.4 with the eyecatcher_id column, i.e., create a dataframe considering only experiments that vary the image. Again, print the length of this new dataframe and how many experiments were discarded in the filtering process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fa9e8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new dataframe length is 7948 and were retained 1719 experiments and 3103 experiments were dropped \n"
     ]
    }
   ],
   "source": [
    "### Packages where there is more than one image \n",
    "#not_unique_image_df = packages.groupby(by=['clickability_test_id']).filter(lambda x : len(x.groupby('eyecatcher_id'))!=1)\n",
    "not_unique_image_df = packages.groupby(by=['clickability_test_id']).filter(lambda x : x['eyecatcher_id'].nunique() != 1)\n",
    "\n",
    "### Number of expermient where there is more than one image \n",
    "not_unique_image_exp_count = not_unique_image_df.groupby('clickability_test_id').count()['created_at'].count()\n",
    "print(\"The new dataframe length is %d and were retained %d experiments and %d experiments were dropped \" % (len(not_unique_image_df), not_unique_image_exp_count,nb_experiment-not_unique_image_exp_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be3f14",
   "metadata": {},
   "source": [
    "1.6 **Discuss:** Considering the answers to questions **T1.4** and **T1.4**, what can we say about the different versions of the news tested by Upworthy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b22f7c",
   "metadata": {},
   "source": [
    "We can safely say that the experiment focuses more on the headlines than the eye catchers since there are more than half experiments are consideing variation of headlines (2586) where less than half experiments are consideing variation of eyecatchers (1719)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d76a6",
   "metadata": {},
   "source": [
    "1.7 For our subsequent analysis, we want to compare the causal effect of headlines on the success of a news piece. \n",
    "For that, we can compare pairs of packages with the same `eyecatcher_id`, `lede`, and `excerpt`, but different `headlines`.\n",
    "Note that this means that if an experiment considered 5 different headlines and did not vary any other stimulus, we would have 5C2 (i.e., 5 choose 2, 10) pairs to consider.\n",
    "Create a dataset where:\n",
    "- each row corresponds to a pair of packages with different `headline` but the same `eyecatcher_id`, `lede`, and `excerpt`. \n",
    "- there are columns containing the headlines of each of the news versions (`headline1`, `headline2`) and the clickthrough rate of each of the news versions (`ctr1`, `ctr2`). \n",
    "- the columns `headline1` and `ctr1` contain the data associated with the news version with the highest clickthrough rate. Print the first columns of your newly created dataframe, as well as its length.\n",
    "-  the columns where the two news pieces had exactly the same clickthrough rate should be filtered out (this is for simplicity's sake).\n",
    "-  the column `date_created` contains the date when the news version with the highest clickthrough rate was created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3044f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_unique_head_df = not_unique_headline_df.groupby(by=['clickability_test_id']).filter(lambda x : x['eyecatcher_id'].nunique() == 1 and x['lede'].nunique() == 1  and x['excerpt'].nunique() == 1  and x['headline'].nunique()== len(x['headline']) )\n",
    "#filtered_unique_head_df = filtered_unique_head_df.dropna(subset=['excerpt','eyecatcher_id','lede'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "544ef4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataSetLength is equal to 17727 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline1</th>\n",
       "      <th>headline2</th>\n",
       "      <th>ctr1</th>\n",
       "      <th>ctr2</th>\n",
       "      <th>date_created</th>\n",
       "      <th>eyecatcher_id</th>\n",
       "      <th>lede</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Science Guy Helps 3 Dudes From America Under...</td>\n",
       "      <td>What They Learned From The Scientist Was Terri...</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>2014-11-20 14:54:18.780</td>\n",
       "      <td>546c7f2dbadeb5788700000a</td>\n",
       "      <td>&lt;p&gt;Some decent guys fighting for an important ...</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What They Learned From The Scientist Was Terri...</td>\n",
       "      <td>He Sat Them Down And Told Them About An Immine...</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>2014-11-20 14:57:52.478</td>\n",
       "      <td>546c7f2dbadeb5788700000a</td>\n",
       "      <td>&lt;p&gt;Some decent guys fighting for an important ...</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The 3 Of Them Needed To See It In Person, And ...</td>\n",
       "      <td>What They Learned From The Scientist Was Terri...</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>2014-11-20 15:13:36.266</td>\n",
       "      <td>546c7f2dbadeb5788700000a</td>\n",
       "      <td>&lt;p&gt;Some decent guys fighting for an important ...</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What They Learned From The Scientist Was Terri...</td>\n",
       "      <td>They May Not Be The Most Handsome Dudes, But T...</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>2014-11-20 14:57:52.478</td>\n",
       "      <td>546c7f2dbadeb5788700000a</td>\n",
       "      <td>&lt;p&gt;Some decent guys fighting for an important ...</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>He Showed Them Some Slides That Freaked Them O...</td>\n",
       "      <td>What They Learned From The Scientist Was Terri...</td>\n",
       "      <td>0.011568</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>2014-11-20 15:09:47.669</td>\n",
       "      <td>546c7f2dbadeb5788700000a</td>\n",
       "      <td>&lt;p&gt;Some decent guys fighting for an important ...</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47044</th>\n",
       "      <td>Ferguson Has Taught Us Many Things. Here's The...</td>\n",
       "      <td>When We Were Young, We Were Taught That Cops W...</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>2014-11-19 22:08:22.857</td>\n",
       "      <td>546c567f545240b352000009</td>\n",
       "      <td>&lt;p&gt;Sad but true: It took the deaths of several...</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47045</th>\n",
       "      <td>A Pen, Paper, And Watercolors Tell One Of The ...</td>\n",
       "      <td>When We Were Young, We Were Taught That Cops W...</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>2014-11-19 22:08:27.941</td>\n",
       "      <td>546c567f545240b352000009</td>\n",
       "      <td>&lt;p&gt;Sad but true: It took the deaths of several...</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47048</th>\n",
       "      <td>An Artist Animates The Ugly Truth We Should Al...</td>\n",
       "      <td>Ferguson Has Taught Us Many Things. Here's The...</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>2014-11-19 22:08:18.431</td>\n",
       "      <td>546c567f545240b352000009</td>\n",
       "      <td>&lt;p&gt;Sad but true: It took the deaths of several...</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47049</th>\n",
       "      <td>A Pen, Paper, And Watercolors Tell One Of The ...</td>\n",
       "      <td>An Artist Animates The Ugly Truth We Should Al...</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>2014-11-19 22:08:27.941</td>\n",
       "      <td>546c567f545240b352000009</td>\n",
       "      <td>&lt;p&gt;Sad but true: It took the deaths of several...</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47053</th>\n",
       "      <td>A Pen, Paper, And Watercolors Tell One Of The ...</td>\n",
       "      <td>Ferguson Has Taught Us Many Things. Here's The...</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>2014-11-19 22:08:27.941</td>\n",
       "      <td>546c567f545240b352000009</td>\n",
       "      <td>&lt;p&gt;Sad but true: It took the deaths of several...</td>\n",
       "      <td>Things that matter. Pass 'em on.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17727 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headline1  \\\n",
       "1      A Science Guy Helps 3 Dudes From America Under...   \n",
       "2      What They Learned From The Scientist Was Terri...   \n",
       "3      The 3 Of Them Needed To See It In Person, And ...   \n",
       "4      What They Learned From The Scientist Was Terri...   \n",
       "5      He Showed Them Some Slides That Freaked Them O...   \n",
       "...                                                  ...   \n",
       "47044  Ferguson Has Taught Us Many Things. Here's The...   \n",
       "47045  A Pen, Paper, And Watercolors Tell One Of The ...   \n",
       "47048  An Artist Animates The Ugly Truth We Should Al...   \n",
       "47049  A Pen, Paper, And Watercolors Tell One Of The ...   \n",
       "47053  A Pen, Paper, And Watercolors Tell One Of The ...   \n",
       "\n",
       "                                               headline2      ctr1      ctr2  \\\n",
       "1      What They Learned From The Scientist Was Terri...  0.012689  0.011101   \n",
       "2      He Sat Them Down And Told Them About An Immine...  0.011101  0.005868   \n",
       "3      What They Learned From The Scientist Was Terri...  0.013795  0.011101   \n",
       "4      They May Not Be The Most Handsome Dudes, But T...  0.011101  0.009726   \n",
       "5      What They Learned From The Scientist Was Terri...  0.011568  0.011101   \n",
       "...                                                  ...       ...       ...   \n",
       "47044  When We Were Young, We Were Taught That Cops W...  0.007845  0.004948   \n",
       "47045  When We Were Young, We Were Taught That Cops W...  0.010920  0.004948   \n",
       "47048  Ferguson Has Taught Us Many Things. Here's The...  0.009219  0.007845   \n",
       "47049  An Artist Animates The Ugly Truth We Should Al...  0.010920  0.009219   \n",
       "47053  Ferguson Has Taught Us Many Things. Here's The...  0.010920  0.007845   \n",
       "\n",
       "                 date_created             eyecatcher_id  \\\n",
       "1     2014-11-20 14:54:18.780  546c7f2dbadeb5788700000a   \n",
       "2     2014-11-20 14:57:52.478  546c7f2dbadeb5788700000a   \n",
       "3     2014-11-20 15:13:36.266  546c7f2dbadeb5788700000a   \n",
       "4     2014-11-20 14:57:52.478  546c7f2dbadeb5788700000a   \n",
       "5     2014-11-20 15:09:47.669  546c7f2dbadeb5788700000a   \n",
       "...                       ...                       ...   \n",
       "47044 2014-11-19 22:08:22.857  546c567f545240b352000009   \n",
       "47045 2014-11-19 22:08:27.941  546c567f545240b352000009   \n",
       "47048 2014-11-19 22:08:18.431  546c567f545240b352000009   \n",
       "47049 2014-11-19 22:08:27.941  546c567f545240b352000009   \n",
       "47053 2014-11-19 22:08:27.941  546c567f545240b352000009   \n",
       "\n",
       "                                                    lede  \\\n",
       "1      <p>Some decent guys fighting for an important ...   \n",
       "2      <p>Some decent guys fighting for an important ...   \n",
       "3      <p>Some decent guys fighting for an important ...   \n",
       "4      <p>Some decent guys fighting for an important ...   \n",
       "5      <p>Some decent guys fighting for an important ...   \n",
       "...                                                  ...   \n",
       "47044  <p>Sad but true: It took the deaths of several...   \n",
       "47045  <p>Sad but true: It took the deaths of several...   \n",
       "47048  <p>Sad but true: It took the deaths of several...   \n",
       "47049  <p>Sad but true: It took the deaths of several...   \n",
       "47053  <p>Sad but true: It took the deaths of several...   \n",
       "\n",
       "                                excerpt  \n",
       "1      Things that matter. Pass 'em on.  \n",
       "2      Things that matter. Pass 'em on.  \n",
       "3      Things that matter. Pass 'em on.  \n",
       "4      Things that matter. Pass 'em on.  \n",
       "5      Things that matter. Pass 'em on.  \n",
       "...                                 ...  \n",
       "47044  Things that matter. Pass 'em on.  \n",
       "47045  Things that matter. Pass 'em on.  \n",
       "47048  Things that matter. Pass 'em on.  \n",
       "47049  Things that matter. Pass 'em on.  \n",
       "47053  Things that matter. Pass 'em on.  \n",
       "\n",
       "[17727 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Join the table with itself using considering 'clickability_test_id', 'eyecatcher_id', 'lede','excerpt' for joining\n",
    "#comparaison = filtered_unique_head_df.merge(filtered_unique_head_df, \n",
    "#                                          on = ['clickability_test_id', 'eyecatcher_id', 'lede','excerpt' ],\n",
    "#                                         how ='inner')\n",
    "\n",
    "comparaison = not_unique_headline_df.merge(not_unique_headline_df, on = ['clickability_test_id', 'eyecatcher_id', 'lede','excerpt' ], how ='inner')\n",
    "\n",
    "\n",
    "### Filtering out rows where clickthrough rate is identical\n",
    "comparaison = comparaison.drop(comparaison[comparaison['ctr_x']==comparaison['ctr_y']].index)\n",
    "\n",
    "### New dataframe  \n",
    "comparaison_final = pd.DataFrame()\n",
    "### Retreiving ids for identification  \n",
    "#comparaison_final['clickability_test_id']= comparaison['clickability_test_id']\n",
    "### Selecting headline1, headline2 , ctr1, ctr2, date_created based on ctr_comapraison criteria  \n",
    "\n",
    "comparaison_final['headline1'] = comparaison.apply(lambda row : row['headline_x'] if row['ctr_x']>row['ctr_y'] else row['headline_y'], axis=1 )\n",
    "comparaison_final['headline2'] = comparaison.apply(lambda row : row['headline_x'] if row['ctr_x']<row['ctr_y'] else row['headline_y'], axis=1 )\n",
    "comparaison_final['ctr1'] = comparaison.apply(lambda row : row['ctr_x'] if row['ctr_x']>row['ctr_y'] else row['ctr_y'], axis=1 )\n",
    "comparaison_final['ctr2'] = comparaison.apply(lambda row : row['ctr_x'] if row['ctr_x']<row['ctr_y'] else row['ctr_y'], axis=1 )\n",
    "comparaison_final['date_created'] = comparaison.apply(lambda row : row['created_at_x'] if row['ctr_x']>row['ctr_y'] else row['created_at_y'], axis=1 )\n",
    "comparaison_final['eyecatcher_id']= comparaison['eyecatcher_id']\n",
    "comparaison_final['lede']= comparaison['lede']\n",
    "comparaison_final['excerpt']= comparaison['excerpt']\n",
    "\n",
    "### Dropping duplicates\n",
    "comparaison_final= comparaison_final.drop_duplicates()\n",
    "print('The DataSetLength is equal to %d ' % len(comparaison_final))\n",
    "comparaison_final\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5471fe7",
   "metadata": {},
   "source": [
    "1.8 To get a sense of the impact of headline change, measure the average difference per pair between the most clicked-through (`ctr1`) and the least clicked-through headline (`ctr2`), as well as the average clickthrough rate for the least clicked through headline (`ctr2`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170cbae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_final['delta_ctr'] = comparaison_final.apply(lambda row : row['ctr1'] - row['ctr2'],axis=1 )\n",
    "\n",
    "print('The average difference per pair between the most clicked-through and the least clicked-through headline is %f and the average clickthrough rate for the least clicked through headline is %f'%(comparaison_final['delta_ctr'].mean(),comparaison_final['ctr2'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00795a15",
   "metadata": {},
   "source": [
    "## Task 2: Extracting signals from the data\n",
    "\n",
    "Your second task is to extract meaningful signals from the data. \n",
    "We start this task from the dataset obtained in **T1.7**. \n",
    "Recall that we have one A/B test per row with the clickthrough rate of two news pieces that differ only in their headline. \n",
    "We refer to the version with the higher clickthrough rate as the \"winner\" and the version with the lower as the \"loser.\" \n",
    "(Note that this is not the same as the column `winner` in the original data, which captures a similar concept but considering the original experiments, where multiple comparisons were made!)\n",
    " \n",
    "2.1 Using the function provided below, count the number of words in each headline, creating columns `numwords1` and `numwords2` corresponding to the number of words in the winner and loser headlines.\n",
    "\n",
    "2.2 Using the dictionary of pronouns provided below, create indicator variables corresponding to each set of pronouns (e.g., first-person singular may yield columns `first_person_singular1` and `first_person_singular2` for the headlines in each A/B test). \n",
    "Each indicator variable in the dataframe should equal 1 if the corresponding headline uses the corresponding type of pronoun and 0 otherwise. \n",
    "Your code should be agnostic to lower/upper case.\n",
    "\n",
    "2.3 One easy way to classify sentiment is simply to match negative or positive words. \n",
    "Use the linked lists of words ([positive][1], [negative][2]) to obtain \"positive sentiment\" and \"negative sentiment\" scores for each headline. Create columns `positive1`/`positive2` and `negative1`/`negative2` containing indicator variables for positive and negative sentiment, i.e., A headline has a \"positive sentiment\" (or negative) score equal 1 if it contains at least one positive (or negative) sentiment word on the list. Otherwise, its \"positive sentiment\" (or negative) score equals 0.\n",
    "    \n",
    "[1]: https://ptrckprry.com/course/ssd/data/positive-words.txt\n",
    "[2]: https://ptrckprry.com/course/ssd/data/negative-words.txt\n",
    "\n",
    "--- \n",
    "\n",
    "**Comments**\n",
    "\n",
    "- For **T2.3**, beware of encodings!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fc40d",
   "metadata": {},
   "source": [
    "2.1 Using the function provided below, count the number of words in each headline, creating columns `numwords1` and `numwords2` corresponding to the number of words in the winner and loser headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a02032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 (provided code)\n",
    "def count_words_simple(x):\n",
    "    return len(x.split(\" \"))\n",
    "str_test = \"How many words are here?\"\n",
    "print(str_test, count_words_simple(str_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db63064",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_final['numwords1'] = comparaison_final.apply(lambda row : count_words_simple(row['headline1']), axis=1)\n",
    "comparaison_final['numwords2'] = comparaison_final.apply(lambda row : count_words_simple(row['headline2']), axis=1)\n",
    "comparaison_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e3a3b6",
   "metadata": {},
   "source": [
    "2.2 Using the dictionary of pronouns provided below, create indicator variables corresponding to each set of pronouns (e.g., first-person singular may yield columns `first_person_singular1` and `first_person_singular2` for the headlines in each A/B test). \n",
    "Each indicator variable in the dataframe should equal 1 if the corresponding headline uses the corresponding type of pronoun and 0 otherwise. \n",
    "Your code should be agnostic to lower/upper case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 (provided code)\n",
    "feature_wordsets = dict([\n",
    "    # https://en.wikipedia.org/wiki/English_personal_pronouns\n",
    "    ('first_person_singular', ['i', 'me', 'my', 'mine', 'myself',\n",
    "                               \"i'd\", \"i'll\", \"i'm\", \"i've\", 'id', 'im', 'ive']),\n",
    "    ('first_person_plural', ['we', 'us', 'our', 'ours', 'ourselves',\n",
    "                              \"we'd\", \"we'll\", \"we're\", \"we've\",]),\n",
    "    ('second_person', ['you','your','yours','yourself',\n",
    "                              \"ya\", \"you'd\", \"you'll\", \"you're\", \"you've\", 'youll', 'youre', 'youve', \n",
    "                              'yourselves']),\n",
    "    ('third_person_singular', ['he','him','his','himself',\n",
    "                               \"he'd\", \"he's\", 'hes',\n",
    "                               'she','her','hers','herself', \n",
    "                               \"she'll\", \"she's\", 'shes',\n",
    "                               'it','its','itself',\n",
    "                               'themself']),\n",
    "    ('third_person_plural', ['they','them','their','theirs','themselves',\n",
    "                              \"they'd\", \"they'll\", \"they've\", 'theyll', 'theyve'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,3): \n",
    "    for key in feature_wordsets : \n",
    "        comparaison_final[key+str(i)]= comparaison_final.apply(lambda row : \n",
    "        0 if len(set(row['headline'+str(i)].lower().split(' ')) & set(feature_wordsets[key]))==0 else 1, axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_final.sort_values(by='ctr1', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ba7300",
   "metadata": {},
   "source": [
    "2.3 One easy way to classify sentiment is simply to match negative or positive words. \n",
    "Use the linked lists of words ([positive][1], [negative][2]) to obtain \"positive sentiment\" and \"negative sentiment\" scores for each headline. Create columns `positive1`/`positive2` and `negative1`/`negative2` containing indicator variables for positive and negative sentiment, i.e., A headline has a \"positive sentiment\" (or negative) score equal 1 if it contains at least one positive (or negative) sentiment word on the list. Otherwise, its \"positive sentiment\" (or negative) score equals 0.\n",
    "    \n",
    "[1]: https://ptrckprry.com/course/ssd/data/positive-words.txt\n",
    "[2]: https://ptrckprry.com/course/ssd/data/negative-words.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4678cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read positive words file\n",
    "with open(data_folder+'positive-words.txt', encoding = \"ISO-8859-1\") as p:\n",
    "    pos = p.readlines()[35:]\n",
    "\n",
    "pos = [s.strip() for s in pos]\n",
    "\n",
    "#read negative words file\n",
    "with open(data_folder+'negative-words.txt', encoding = \"ISO-8859-1\") as n:\n",
    "    neg = n.readlines()[35:]\n",
    "\n",
    "neg = [s.strip() for s in neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_final['positive1'] = comparaison_final.apply(lambda row : 0 if len(set(row['headline1'].lower().split(' ')) & set(pos))==0 else 1,axis=1)\n",
    "comparaison_final['positive2'] = comparaison_final.apply(lambda row : 0 if len(set(row['headline2'].lower().split(' ')) & set(pos))==0 else 1,axis=1)\n",
    "comparaison_final['negative1'] = comparaison_final.apply(lambda row : 0 if len(set(row['headline1'].lower().split(' ')) & set(neg))==0 else 1,axis=1)\n",
    "comparaison_final['negative2'] = comparaison_final.apply(lambda row : 0 if len(set(row['headline2'].lower().split(' ')) & set(neg))==0 else 1,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f0b46",
   "metadata": {},
   "source": [
    "## Task 3: Estimating the effect of language on headline success\n",
    "\n",
    "Your third task revolves around the question *how does language impact headlines' success?*\n",
    "\n",
    "3.1 First, we examine whether the winner headlines have more or fewer words than the loser headline. Conduct an independent sample t-test and paired t-test (see [scipy.stats](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html#scipy.stats.ttest_ind); for the independent sample t-test, assume equal variance). Also, calculate and print the mean difference between the number of words in the winner and the loser headlines.\n",
    "\n",
    "3.2 **Discuss:** Are longer headlines more successful? Justify.\n",
    "\n",
    "3.3 The [t-statistic](https://en.wikipedia.org/wiki/T-statistic) is the ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error. In a t-test, the higher the t-statistic, the more confidently we can reject the null hypothesis. Use `numpy.random` to create four samples, each of size 30:\n",
    "- $X \\sim Uniform(0,1)$\n",
    "- $Y \\sim Uniform(0,1)$\n",
    "- $Z = X/2 + Y/2 + 0.1$\n",
    "- $K = Y + 0.1$\n",
    "    \n",
    "3.4 **Discuss:** What are the expected values and the variance of $X$, $Y$, $Z$, and $K$? (You don't need to justify them!)\n",
    "\n",
    "3.5 Run the following simulation 10000 times, storing the $p$-values for the tests at each run:\n",
    "- Sample new values  for $X$, $Y$, $Z$ and $K$ ($n=30$ each). \n",
    "- Run independent sample t-test (assuming equal variance) and paired t-test comparing $X$ and $Z$.\n",
    "-  Run independent sample t-test (assuming equal variance) and paired t-test comparing $X$ and $K$.\n",
    "\n",
    "3.6 Recall that the power of a binary hypothesis test is the probability that the test correctly rejects the null hypothesis when the alternative hypothesis is true. Using the p-values and assuming that we reject the null hypothesis if $p < 0.05$, calculate the statistical power of:\n",
    "- The independent sample t-test comparing $X$ and $Z$.\n",
    "- The paired t-test comparing $X$ and $Z$.\n",
    "- The independent sample t-test comparing $X$ and $K$.\n",
    "- The paired t-test comparing $X$ and $K$.\n",
    "    \n",
    "3.7 **Discuss:** When are paired t-tests helpful? Justify.\n",
    "\n",
    "3.8 With a bootstrapping approach (implemented by yourself, you should not use existing bootstrapping functions), estimate the average difference and 95% confidence intervals for:\n",
    "- the mean ratio between the number of words in the winner headline and the loser headline (i.e., the number of words in the winner headline divided by the number of words in the loser headlines).\n",
    "- the difference in usage of positive words between winner and loser headlines.\n",
    "- the difference in usage of negative words between winner and loser headlines.\n",
    "- The difference in usage of each type of pronoun between winner and loser headlines.\n",
    "\n",
    "3.9 **Discuss:** According to the results obtained in **T3.8**, what headlines grab people's attention the most? Justify your answer.\n",
    "    \n",
    "---\n",
    "**Comments:**\n",
    "\n",
    "- Paired t-test formula: $t = \\frac{\\overline{x}_{\\mathrm{diff}}}{s_{\\mathrm{diff}} / \\sqrt n }$ where:\n",
    "    - $\\overline{x}_{\\mathrm{diff}}$ is the sample difference between the means of the matched sample; and\n",
    "    - $s_{\\mathrm{diff}}$ is the sample variance of the matched sample; and\n",
    "    - $n$ is the number of matched samples.\n",
    "    \n",
    "- Independent samples t-test formula: $t = \\frac{\\overline{x}_{1} - \\overline{x}_{2}}{\\sqrt{\\frac{s_{1}^{2}}{n_{1}} + \\frac{s_{2}^{2}}{n_{2}}}}$ where:\n",
    "    - $\\overline{x}_{\\mathrm{1}}$ is the sample mean of the first group; and\n",
    "    - $s_{\\mathrm{1}}$ is the sample variance of the first group; and\n",
    "    - $n_1$ is the number of samples in the first group;\n",
    "    \n",
    "     \n",
    "- t-tests are valid for samples of non-normal distribution for large enough samples (a rule of thumb used is: n$\\geq$30)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5d7d6",
   "metadata": {},
   "source": [
    "**3.1** First, we examine whether the winner headlines have more or fewer words than the loser headline. Conduct an independent sample t-test and paired t-test (see scipy.stats; for the independent sample t-test, assume equal variance). Also, calculate and print the mean difference between the number of words in the winner and the loser headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96960e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Independent samples t-test\n",
    "ind_t_test = ttest_ind(comparaison_final['numwords1'],comparaison_final['numwords2'],equal_var=True)\n",
    "\n",
    "### Paired t-test\n",
    "paired_t_test = ttest_rel(comparaison_final['numwords1'],comparaison_final['numwords2'])\n",
    "\n",
    "### Diff in legth between winner and looser headdline \n",
    "diff = comparaison_final['numwords1'] - comparaison_final['numwords2']\n",
    "mean_diff = (diff).mean()\n",
    "var_diff = (diff).var()\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle('Distribution of the number of pair of headline as a function of the differnce in length between winner and looser headline ')\n",
    "ax1.hist(diff.values, bins = 100 )\n",
    "\n",
    "### TODO Should we keep yscale = \"log\" ?\n",
    "\n",
    "ax1.set(xlabel='Difference in length between winner and looser headline', ylabel=\"Number of pair of headline\") \n",
    "ax2.boxplot(diff.values)\n",
    "ax2 = ax2.set(xticks=[])\n",
    "\n",
    "\n",
    "print('Independent t-test results =>  Statistics : %0.2f , pvalue: %1.2E' % (ind_t_test[0],  ind_t_test[1]))    \n",
    "print('Paired t-test results =>  Statistics : %0.2f , pvalue: %1.2E' % (paired_t_test[0],  paired_t_test[1]))\n",
    "print('The mean difference is equal to %0.2f words, and the variance is equal to %0.2f' % (mean_diff,var_diff) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc04e3b7",
   "metadata": {},
   "source": [
    "**3.2 Discuss:** Are longer headlines more successful? Justify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5c18ac",
   "metadata": {},
   "source": [
    "Paired t-test : $ (p_{value} < 0.05)  \\Rightarrow$ we can reject the null hypothesis of identical average headline length. \n",
    "\n",
    "Independent t-test : $ (p_{value} < 0.05)  \\Rightarrow$ we can reject the null hypothesis of identical average headline length. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb770b9",
   "metadata": {},
   "source": [
    "**3.3** The [t-statistic](https://en.wikipedia.org/wiki/T-statistic) is the ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error. In a t-test, the higher the t-statistic, the more confidently we can reject the null hypothesis. Use `numpy.random` to create four samples, each of size 30:\n",
    "- $X \\sim Uniform(0,1)$\n",
    "- $Y \\sim Uniform(0,1)$\n",
    "- $Z = X/2 + Y/2 + 0.1$\n",
    "- $K = Y + 0.1$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(low=0,high=1,size=30)\n",
    "y = np.random.uniform(low=0,high=1,size=30)\n",
    "z = x/2 + y/2 + 0.1\n",
    "k = y + 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c35a9b1",
   "metadata": {},
   "source": [
    "**3.4 Discuss:** What are the expected values and the variance of $X$, $Y$, $Z$, and $K$? (You don't need to justify them!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d1d88",
   "metadata": {},
   "source": [
    "$Var[X] = E[(X)^2] - E[X]^2 = \\frac{1}{3} - \\frac{1}{4} = \\frac{1}{12} $ \n",
    "\n",
    "$Var[Y] = \\frac{1}{12} $\n",
    "\n",
    "$Var[Z] = Var[\\frac{X}{2}+ \\frac{Y}{2} + 0.1] = Var[\\frac{X}{2}] + Var[\\frac{Y}{2}]= \\frac{1}{4} (Var[X]+ Var[Y])= \\frac{1}{24}   $\n",
    "\n",
    "$Var[K] = Var[Y + 0.1]=  Var[Y ]=  \\frac{1}{12} $ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc838372",
   "metadata": {},
   "source": [
    "**3.5** Run the following simulation 10000 times, storing the $p$-values for the tests at each run:\n",
    "- Sample new values  for $X$, $Y$, $Z$ and $K$ ($n=30$ each). \n",
    "- Run independent sample t-test (assuming equal variance) and paired t-test comparing $X$ and $Z$.\n",
    "-  Run independent sample t-test (assuming equal variance) and paired t-test comparing $X$ and $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 10000\n",
    "p_values_ind_x_z = []\n",
    "p_values_paired_x_z = []\n",
    "p_values_ind_x_k = []\n",
    "p_values_paired_x_k = []\n",
    "p_values_paired_x_mehdi = []\n",
    "p_values_ind_x_mehdi = []\n",
    "for i in range(n_iters):\n",
    "    x = np.random.uniform(low=0,high=1,size=30)\n",
    "    y = np.random.uniform(low=0,high=1,size=30)\n",
    "    z = x/2 + y/2 + 0.1\n",
    "    k = y + 0.1\n",
    "    p_values_ind_x_z.append(ttest_ind(x,z,equal_var=True).pvalue)\n",
    "    p_values_paired_x_z.append(ttest_rel(x,z).pvalue)\n",
    "    p_values_ind_x_k.append(ttest_ind(x,k,equal_var=True).pvalue)\n",
    "    p_values_paired_x_k.append(ttest_rel(x,k).pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7e7e6",
   "metadata": {},
   "source": [
    "**3.6** Recall that the power of a binary hypothesis test is the probability that the test correctly rejects the null hypothesis when the alternative hypothesis is true. Using the p-values and assuming that we reject the null hypothesis if $p < 0.05$, calculate the statistical power of:\n",
    "- The independent sample t-test comparing $X$ and $Z$.\n",
    "- The paired t-test comparing $X$ and $Z$.\n",
    "- The independent sample t-test comparing $X$ and $K$.\n",
    "- The paired t-test comparing $X$ and $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac260993",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_power_ind_x_z = len([x  for x  in p_values_ind_x_z if x < 0.05 ])/n_iters\n",
    "stat_power_paired_x_z = len([x  for x  in p_values_paired_x_z if x < 0.05 ])/n_iters\n",
    "\n",
    "stat_power_ind_x_k = len([x  for x  in p_values_ind_x_k if x < 0.05 ])/n_iters\n",
    "stat_power_paired_x_k = len([x  for x  in p_values_paired_x_k if x < 0.05 ])/n_iters\n",
    "\n",
    "print('The independent sample t-test comparing X and Z : %0.2f' % stat_power_ind_x_z)\n",
    "print('The paired t-test comparing X and Z : %0.2f' % stat_power_paired_x_z)\n",
    "print('The independent sample t-test comparing X and K : %0.2f' % stat_power_ind_x_k)\n",
    "print('The paired t-test comparing X and K : %0.2f' % stat_power_paired_x_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f77ca1",
   "metadata": {},
   "source": [
    "**3.7 Discuss:** When are paired t-tests helpful? Justify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97811574",
   "metadata": {},
   "source": [
    "Paired t-test are useful when comparing variables from matched pairs, i.e., there exist a (temporal, logical, etc. ) relationship between the pairs of random variables.\n",
    "\n",
    "We can see that paired t-test are statistically stronger when applied on Z and X, which are related random variables, with $ P( $ reject $H_0 | H_1 $is true $) = 0.74 $ compared to when applied on X and K which are not related at all, with $ P( $ reject $H_0 | H_1 $is true $) = 0.26 $. \n",
    "\n",
    "In this particular case paired t-test are statsitically as strong as independent sample t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a201e0a",
   "metadata": {},
   "source": [
    "**3.8** With a bootstrapping approach (implemented by yourself, you should not use existing bootstrapping functions), estimate the average difference and 95% confidence intervals for:\n",
    "- the mean ratio between the number of words in the winner headline and the loser headline (i.e., the number of words in the winner headline divided by the number of words in the loser headlines).\n",
    "- the difference in usage of positive words between winner and loser headlines.\n",
    "- the difference in usage of negative words between winner and loser headlines.\n",
    "- The difference in usage of each type of pronoun between winner and loser headlines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681651e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_confidence_interval_in_list(means_list):\n",
    "    return (np.quantile(means_list,0.025),np.quantile(means_list,0.975))\n",
    "\n",
    "def batch_iter(series, batch_size, num_batches):\n",
    "    data_size = len(series)\n",
    "    shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "    shuffled_series = series[series.index.values[shuffle_indices]]\n",
    "    for batch_num in range(num_batches):\n",
    "        strt = np.random.randint(data_size-batch_size)\n",
    "        start_index = min(shuffle_indices[strt], shuffle_indices[strt]-batch_size)\n",
    "        end_index = start_index + batch_size\n",
    "        if start_index != end_index:\n",
    "            yield shuffled_series[start_index:end_index].values\n",
    "            \n",
    "def calculate_means(batches):\n",
    "    batches = filter(lambda x : len(x)!=0, batches)\n",
    "    means_array = []\n",
    "    for  batch in batches :\n",
    "        means_array.append(np.mean(batch))\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=1)\n",
    "    axs.hist(means_array, bins = 100)\n",
    "    return means_array\n",
    "\n",
    "def confidence_interval(serie, batch_size=100, num_batches = 10000):\n",
    "    batches = list(batch_iter(serie,batch_size,num_batches ))\n",
    "    means = calculate_means(batches)\n",
    "    return find_confidence_interval_in_list(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a081fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "ci_mean_ratio = confidence_interval(comparaison_final['numwords1']/comparaison_final['numwords2'])\n",
    "print('ci_mean_ratio [%1.4f, %1.4f]' %ci_mean_ratio )\n",
    "print()\n",
    "#2\n",
    "ci_pos_words = confidence_interval(comparaison_final['positive1']-comparaison_final['positive2'])\n",
    "print('ci_pos_words [%1.4f, %1.4f]' %ci_pos_words)\n",
    "avg_diff_pos_words = (comparaison_final['positive1']-comparaison_final['positive2']).mean()\n",
    "var_diff_pos_words = (comparaison_final['positive1']-comparaison_final['positive2']).var()\n",
    "print('avg_diff_pos_words %1.4f, var_diff_pos_words %1.4f ' % (avg_diff_pos_words, var_diff_pos_words))\n",
    "print()\n",
    "#3\n",
    "ci_neg_words = confidence_interval(comparaison_final['negative1']-comparaison_final['negative2'])\n",
    "print('ci_neg_words [%1.4f, %1.4f]' %ci_neg_words )\n",
    "avg_diff_neg_words = (comparaison_final['negative1']-comparaison_final['negative2']).mean()\n",
    "var_diff_neg_words = (comparaison_final['negative1']-comparaison_final['negative2']).var()\n",
    "print('avg_diff_neg_words %1.4f, , var_diff_pos_words %1.4f' %(avg_diff_neg_words,var_diff_neg_words))\n",
    "print(),\n",
    "\n",
    "ci_prononouns = {}\n",
    "avg_diff_pronouns = {}\n",
    "var_diff_pronouns = {}\n",
    "for key in feature_wordsets : \n",
    "    ci_prononouns[key]= confidence_interval(comparaison_final[key+'1'] -  comparaison_final[key+'2'] )\n",
    "    print('ci_neg_words [%1.4f, %1.4f]' %ci_prononouns[key])\n",
    "    avg_diff_pronouns[key]=(comparaison_final[key+'1'] -  comparaison_final[key+'2'] ).mean()\n",
    "    var_diff_pronouns[key]=(comparaison_final[key+'1'] -  comparaison_final[key+'2'] ).var()\n",
    "    print('avg_diff_pronouns[key] %1.4f, var_diff_pronouns[key] %1.4f ' %(avg_diff_pronouns[key], var_diff_pronouns[key]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70888d20",
   "metadata": {},
   "source": [
    "## Task 4: Temporal validity and heterogeneity of the effect.\n",
    "\n",
    "Last, we investigate how the effects studied in **T3** change with time and how they might be heterogeneous across different types of news.\n",
    "\n",
    "4.1 Create a plot where you depict the monthly average number of words in winner and loser headlines. Consider only headlines created after April 2013 (the month of April inclusive). Include also bootstrapped 95% confidence intervals; here, you can use a third-party implementation if you want. Finally, recall that we created a column `date_created` which captures the creation of the winner headline; you can consider this date to correspond to the date of the creation of the A/B test.\n",
    "\n",
    "4.2 Produce similar plots to each pronoun category, as well as for positive and negative sentiment. Here, unlike in **T4.1**, depict the month averages pooled across winner and loser headlines (i.e., for each month, you calculate the average across both winners and loser headlines).\n",
    "Create all these plots in a single figure with no more than 11 inches of width and 11 inches of height. Again, consider only headlines created after April 2013 (the month of April inclusive).\n",
    "\n",
    "4.3 **Discuss:** Has the type of headline Upworthy used in their A/B tests changed with time? Are these changes likely to be producing more or less engaging headlines? Justify.\n",
    "\n",
    "4.4 Divide your data into two periods, $t_1$, which goes from  April 2013 (inclusive) to March 2014 (inclusive), and $t_2$, which goes from April 2014 (inclusive) to the latest A/B test in the data. Create a dataframe for A/B tests in each period.\n",
    "\n",
    "4.5 Let's examine if the effects observed remained the same throughout the study period. Use an appropriate methodology  of your choice to determine if the effects observed in **T3.8** (length, each category of pronouns, positive words, and negative words) were different in $t_1$ and $t_2$. Here, note that we are considering \"at least one positive outcome\" to be the manifestation of an underlying effect, thus significance level must be adjusted down when performing multiple hypothesis tests!\n",
    "\n",
    "4.6 **Discuss:** Hypothesize two reasons that could have led to a change in the observed effects. According to the analysis done in **T4.5**, have the effects observed remained the same across the study period? \n",
    "\n",
    "4.7 The features we are studying may interact with each other. For instance, people may like first person singular pronouns in headlines containing positive words (you are amazing!), but dislike headlines with negative words and first person pronouns (you are awful!). To help answer this question, create:\n",
    "- a dataframe containing all A/B tests where both winner and loser headlines include a positive word; and\n",
    "- a dataframe containing all A/B tests where both winner and loser headlines include a negative word;\n",
    "\n",
    "4.8 Using an appropriate methodology of your choice, determine if the effect of the use of first person singular pronouns in the headline is heterogeneous across headlines with positive words and negative words, i.e., is the effect significantly stronger for one of the dataframes created in **T4.7**? \n",
    "\n",
    "4.9 **Discuss:** Considering the analyses you did throughout Tasks 3 and 4, write a short text (no more than 250 words) giving advice to Upworthy employees on how they should try to write engaging headlines. \n",
    "You can reference images present in the notebook by indicating a task (e.g., image plotted in **T3.3**) or a cell number. Note that you do not need to conduct any additional analysis to write this text. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85236f9a",
   "metadata": {},
   "source": [
    "4.1 Create a plot where you depict the monthly average number of words in winner and loser headlines. Consider only headlines created after April 2013 (the month of April inclusive). Include also bootstrapped 95% confidence intervals; here, you can use a third-party implementation if you want. Finally, recall that we created a column `date_created` which captures the creation of the winner headline; you can consider this date to correspond to the date of the creation of the A/B test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_final['date_created'] = comparaison_final['date_created'].astype('datetime64[ns]')\n",
    "after_april2013 = comparaison_final[comparaison_final['date_created'] >= '2013-04-01']\n",
    "comparaison_final_month = after_april2013.groupby([after_april2013['date_created'].dt.month, after_april2013['date_created'].dt.year])\n",
    "\n",
    "\n",
    "def bootstrap_CI(data, nbr_draws):\n",
    "    means = np.zeros(nbr_draws)\n",
    "    data = np.array(data)\n",
    "\n",
    "    for n in range(nbr_draws):\n",
    "        indices = np.random.randint(0, len(data), len(data))\n",
    "        data_tmp = data[indices] \n",
    "        means[n] = np.nanmean(data_tmp)\n",
    "\n",
    "    return [np.nanpercentile(means, 2.5),np.nanpercentile(means, 97.5)]\n",
    "\n",
    "\n",
    "stats_by_month1 = comparaison_final_month.apply(lambda x: pd.Series({\n",
    "        'average_numwords1': x['numwords1'].mean(),\n",
    "        'lower_err_numwords1': bootstrap_CI(x['numwords1'], 1000)[0],\n",
    "        'upper_err_numwords2': bootstrap_CI(x['numwords1'], 1000)[1]\n",
    "    }))   \n",
    "\n",
    "stats_by_month2 = comparaison_final_month.apply(lambda x: pd.Series({\n",
    "        'average_numwords2': x['numwords2'].mean(),\n",
    "        'lower_err_numwords2': bootstrap_CI(x['numwords2'], 1000)[0],\n",
    "        'upper_err_numwords2': bootstrap_CI(x['numwords2'], 1000)[1]\n",
    "    }))\n",
    "\n",
    "stats_by_month1 = stats_by_month1.sort_index(level=[1,0])\n",
    "stats_by_month2 = stats_by_month2.sort_index(level=[1,0])\n",
    "\n",
    "stats_by_month1.index = stats_by_month1.index.map(lambda x : str(x[0]) + '-' + str(x[1]))\n",
    "stats_by_month2.index = stats_by_month2.index.map(lambda x : str(x[0]) + '-' + str(x[1]))\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(13, 5))\n",
    "ax.errorbar(stats_by_month1.index, stats_by_month1.average_numwords1,\n",
    "             yerr = [-stats_by_month1.lower_err_numwords1 + stats_by_month1.average_numwords1, \n",
    "                    -stats_by_month1.average_numwords1 + stats_by_month1.upper_err_numwords2],\n",
    "             capsize= 3)\n",
    "ax.errorbar(stats_by_month2.index, stats_by_month2.average_numwords2,\n",
    "                yerr = [-stats_by_month2.lower_err_numwords2 + stats_by_month2.average_numwords2,\n",
    "                          -stats_by_month2.average_numwords2 + stats_by_month2.upper_err_numwords2],\n",
    "                capsize= 3)\n",
    "\n",
    "ax.set_xticks(stats_by_month1.index)\n",
    "ax.set_xticklabels(stats_by_month1.index, rotation=45)\n",
    "ax.set_xlabel('Month-Year')\n",
    "ax.set_ylabel('Average number of words')\n",
    "ax.set_title('Average number of words per month')\n",
    "ax.legend(['Winners', 'Loosers'])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73062509",
   "metadata": {},
   "source": [
    "4.2 Produce similar plots to each pronoun category, as well as for positive and negative sentiment. Here, unlike in **T4.1**, depict the month averages pooled across winner and loser headlines (i.e., for each month, you calculate the average across both winners and loser headlines).\n",
    "Create all these plots in a single figure with no more than 11 inches of width and 11 inches of height. Again, consider only headlines created after April 2013 (the month of April inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(15, 8))  #check if less than 11x11 inches\n",
    "\n",
    "for key in feature_wordsets : \n",
    "    comparaison_final[key] = comparaison_final[key+'1'] + comparaison_final[key+'2']\n",
    "    after_april2013 = comparaison_final[comparaison_final['date_created'] >= '2013-04-01']\n",
    "    comparaison_final_month = after_april2013.groupby([after_april2013['date_created'].dt.month, after_april2013['date_created'].dt.year])\n",
    "\n",
    "    stats_by_month = comparaison_final_month.apply(lambda x: pd.Series({\n",
    "        'average_'+key: x[key].mean(),\n",
    "        'lower_err_'+key: bootstrap_CI(x[key], 1000)[0],\n",
    "        'upper_err_'+key: bootstrap_CI(x[key], 1000)[1]\n",
    "    }))\n",
    "\n",
    "    stats_by_month = stats_by_month.sort_index(level=[1,0])\n",
    "    stats_by_month.index = stats_by_month.index.map(lambda x : str(x[0]) + '-' + str(x[1]))\n",
    "\n",
    "    ax.errorbar(stats_by_month.index, stats_by_month['average_'+key],\n",
    "                yerr = [-stats_by_month['lower_err_'+key] + stats_by_month['average_'+key],\n",
    "                        -stats_by_month['average_'+key] + stats_by_month['upper_err_'+key]],\n",
    "                capsize= 3)\n",
    "\n",
    "    #comparaison_final.drop(key, axis=1, inplace=True)\n",
    "\n",
    "comparaison_final['positive'] = comparaison_final['positive1'] + comparaison_final['positive2']\n",
    "comparaison_final['negative'] = comparaison_final['negative1'] + comparaison_final['negative2']\n",
    "after_april2013 = comparaison_final[comparaison_final['date_created'] >= '2013-04-01']\n",
    "comparaison_final_month = after_april2013.groupby([after_april2013['date_created'].dt.month, after_april2013['date_created'].dt.year])\n",
    "\n",
    "stats_pos = comparaison_final_month.apply(lambda x: pd.Series({\n",
    "        'average_positive': x['positive'].mean(),\n",
    "        'lower_err_positive': bootstrap_CI(x['positive'], 1000)[0],\n",
    "        'upper_err_positive': bootstrap_CI(x['positive'], 1000)[1]\n",
    "    }))\n",
    "stats_neg = comparaison_final_month.apply(lambda x: pd.Series({\n",
    "        'average_negative': x['negative'].mean(),\n",
    "        'lower_err_negative': bootstrap_CI(x['negative'], 1000)[0],\n",
    "        'upper_err_negative': bootstrap_CI(x['negative'], 1000)[1]\n",
    "    }))\n",
    "\n",
    "stats_pos = stats_pos.sort_index(level=[1,0])\n",
    "stats_neg = stats_neg.sort_index(level=[1,0])\n",
    "\n",
    "stats_pos.index = stats_pos.index.map(lambda x : str(x[0]) + '-' + str(x[1]))\n",
    "stats_neg.index = stats_neg.index.map(lambda x : str(x[0]) + '-' + str(x[1]))\n",
    "\n",
    "ax.errorbar(stats_pos.index, stats_pos.average_positive,\n",
    "            yerr = [-stats_pos.lower_err_positive + stats_pos.average_positive,\n",
    "                    -stats_pos.average_positive + stats_pos.upper_err_positive],\n",
    "            capsize= 3)\n",
    "ax.errorbar(stats_neg.index, stats_neg.average_negative,\n",
    "            yerr = [-stats_neg.lower_err_negative + stats_neg.average_negative,\n",
    "                    -stats_neg.average_negative + stats_neg.upper_err_negative],\n",
    "            capsize= 3)\n",
    "\n",
    "#comparaison_final.drop(['positive', 'negative'], axis=1, inplace=True)\n",
    "\n",
    "ax.set_xticks(stats_by_month1.index)\n",
    "ax.set_xticklabels(stats_by_month1.index, rotation=45)\n",
    "ax.set_xlabel('Month-Year')\n",
    "ax.set_ylabel('Average number of words')\n",
    "ax.legend(list(feature_wordsets) + ['positive', 'negative'], loc='upper right', bbox_to_anchor=(1.2, 1), )\n",
    "ax.set_title('Average number of words per category per month')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f0d09f",
   "metadata": {},
   "source": [
    "4.3 **Discuss:** Has the type of headline Upworthy used in their A/B tests changed with time? Are these changes likely to be producing more or less engaging headlines? Justify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a475ae55",
   "metadata": {},
   "source": [
    "We note that the average number of words has increased over time in both winner and looser headlines.\n",
    "This is likely to produce more engaging headlines, as the average number of words in winner headlines is higher than the average number of words in loser headlines.\n",
    "\n",
    "We also note that the average number of negative words has decreased lately in both winner and looser headlines.\n",
    "The use of second person pronouns has also decreased in both winner and looser headlines whereas the use of third person pronouns has increased.\n",
    "Headlines tend thus to be more positive and less personal over time. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31171951",
   "metadata": {},
   "source": [
    "4.4 Divide your data into two periods, $t_1$, which goes from  April 2013 (inclusive) to March 2014 (inclusive), and $t_2$, which goes from April 2014 (inclusive) to the latest A/B test in the data. Create a dataframe for A/B tests in each period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54660e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_final['length'] = (comparaison_final['numwords1'] + comparaison_final['numwords2'])/2\n",
    "t1 = comparaison_final[(comparaison_final['date_created'] >= '2013-04-01') & (comparaison_final['date_created'] <= '2014-03-31')]\n",
    "t2 = comparaison_final[comparaison_final['date_created'] >= '2014-04-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d1068",
   "metadata": {},
   "outputs": [],
   "source": [
    "min = t1['date_created'].min()\n",
    "max = t1['date_created'].max()\n",
    "print((str(min), str(max)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8985a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "min = t2['date_created'].min()\n",
    "max = t2['date_created'].max()\n",
    "print((str(min), str(max)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705247ed",
   "metadata": {},
   "source": [
    "4.5 Let's examine if the effects observed remained the same throughout the study period. Use an appropriate methodology  of your choice to determine if the effects observed in **T3.8** (length, each category of pronouns, positive words, and negative words) were different in $t_1$ and $t_2$. Here, note that we are considering \"at least one positive outcome\" to be the manifestation of an underlying effect, thus significance level must be adjusted down when performing multiple hypothesis tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438356fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest = ttest_ind(t1['length'], t2['length'])\n",
    "print(\"length: t-test= {0:.3f}, p-value= {1:.3f}\".format(ttest[0], ttest[1]))\n",
    "\n",
    "for key in feature_wordsets : \n",
    "    ttest = ttest_ind(t1[key], t2[key])\n",
    "    print(\"{}: t-test={}, p-value={}\".format(key, ttest[0], ttest[1]))\n",
    "    #comparaison_final.drop(key, axis=1, inplace=True)\n",
    "\n",
    "ttest = ttest_ind(t1['positive'], t2['positive'])\n",
    "print(\"positive: t-test= {0:.3f}, p-value= {1:.3f}\".format(ttest[0], ttest[1]))\n",
    "ttest = ttest_ind(t1['negative'], t2['negative'])\n",
    "print(\"negative: t-test= {0:.3f}, p-value= {1:.3f}\".format(ttest[0], ttest[1]))\n",
    "\n",
    "#comparaison_final.drop(['length', 'positive', 'negative'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f9e6c",
   "metadata": {},
   "source": [
    "4.6 **Discuss:** Hypothesize two reasons that could have led to a change in the observed effects. According to the analysis done in **T4.5**, have the effects observed remained the same across the study period? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da35fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2c971ab",
   "metadata": {},
   "source": [
    "4.7 The features we are studying may interact with each other. For instance, people may like first person singular pronouns in headlines containing positive words (you are amazing!), but dislike headlines with negative words and first person pronouns (you are awful!). To help answer this question, create:\n",
    "- a dataframe containing all A/B tests where both winner and loser headlines include a positive word; and\n",
    "- a dataframe containing all A/B tests where both winner and loser headlines include a negative word;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f64b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_looser_pos = comparaison_final[(comparaison_final['positive1'] > 0) & (comparaison_final['positive2'] > 0)]\n",
    "winner_looser_neg = comparaison_final[(comparaison_final['negative1'] > 0) & (comparaison_final['negative2'] > 0)]\n",
    "print(\"There are {} A/B tests where both headlines include at least a positive word\".format(len(winner_looser_pos)))\n",
    "print(\"There are {} A/B tests where both headlines include at least a negative word\".format(len(winner_looser_neg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cde2a",
   "metadata": {},
   "source": [
    "4.8 Using an appropriate methodology of your choice, determine if the effect of the use of first person singular pronouns in the headline is heterogeneous across headlines with positive words and negative words, i.e., is the effect significantly stronger for one of the dataframes created in **T4.7**? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest = ttest_ind(winner_looser_pos['first_person_singular'], winner_looser_neg['first_person_singular'])\n",
    "print(\"first_person_singular: t-test= {0:.3f}, p-value= {1:.3f}\".format(ttest[0], ttest[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ae25f",
   "metadata": {},
   "source": [
    "4.9 **Discuss:** Considering the analyses you did throughout Tasks 3 and 4, write a short text (no more than 250 words) giving advice to Upworthy employees on how they should try to write engaging headlines. \n",
    "You can reference images present in the notebook by indicating a task (e.g., image plotted in **T3.3**) or a cell number. Note that you do not need to conduct any additional analysis to write this text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3dc9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1dcd94874888b7875c65b06e8db780edc36f818ca50cec7c0a5f76917c081af1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
